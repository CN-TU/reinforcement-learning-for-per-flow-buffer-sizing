\documentclass[10pt,sigconf,letterpaper,anonymous]{acmart}

\usepackage[english]{babel}
\usepackage{blindtext}

%Conference Info
\acmYear{2020}
\copyrightyear{2020}
%\setcopyright{acmcopyright}
\acmConference{CoNEXT '20}{December 1-4, 2020}{Barcelona, Spain}
%\acmPrice{TBA}
%\acmDOI{TBA}
%\acmISBN{TBA}

\usepackage[nomain, toc, acronym]{glossaries}
\usepackage{subfig}
\usepackage{booktabs}

\newacronym{dl}{DL}{Deep Learning}
\newacronym{rl}{RL}{Reinforcement Learning}
\newacronym{ours}{OurSolution}{OurSolution}
\newacronym{cca}{CCA}{Congestion Control Algorithms}
\newacronym{aqm}{AQM}{Active Queue Management}
\newacronym{rtt}{RTT}{Round Trip Time}
\newacronym{fq}{FQ}{Fair Queuing}
\newacronym{ml}{ML}{Machine Learning}
\newacronym{bdp}{BDP}{Bandwidth Delay Product}
\newacronym{mae}{MAE}{Mean Absolute Error}
\newacronym{mse}{MSE}{Mean Squared Error}



\newcommand{\mynote}[3]{
    \fbox{\bfseries\sffamily\scriptsize#1}
    {\small$\blacktriangleright$\textsf{\emph{\color{#3}{#2}}}$\blacktriangleleft$}}

\newcommand{\todo}[1]{\mynote{TODO}{#1}{red}}

\begin{document}
\title{Online Learning Per-flow Queuing Policies}

%\subtitle{Paper \# XXX, XXX pages}
% \author{Firstname Lastname}
% \authornote{Note}
% \orcid{1234-5678-9012}
% \affiliation{%
%   \institution{Affiliation}
%   \streetaddress{Address}
%   \city{City} 
%   \state{State} 
%   \postcode{Zipcode}
% }
% \email{email@domain.com}


\begin{abstract}
The increasing number of different, incompatible congestion control algorithms has led to an increased deployment of fair queuing. Fair queuing isolates each network flow and gives it a separate queue. It can thus guarantee fairness for each flow even if the flows' congestion controls are not inherently fair. So far, each queue in the fair queuing system either has a fixed, static maximum size or is managed by an Active Queue Management algorithm (AQM) like CoDel. In this paper we design and implement an AQM mechanism that dynamically learns the optimal buffer size for each flow with respect to a specified utility function. We show that our Deep Learning based algorithm can correctly fingerprint each flow and assign the optimal queue size. Besides that we also show that our mechanism can even learn completely on-line and can continuously adapt. Finally we demonstrate that the computational overhead of our approach is sufficiently low to allow for deployment on regular hardware. 
\end{abstract}

\maketitle

\section{Introduction}

New \gls{cca} for TCP and QUIC are still being introduced, with one of the most prominent ones in recent years being BBR \cite{cardwell_bbr:_2016}\todo{Add more refs}. While new \glspl{cca} are commonly being designed with compatibility to other \glspl{cca} in mind, often they do not share the link completely fairly with older \glspl{cca}\todo{Add more refs}. Besides that, network flows using the same \gls{cca} can also be unfair to each other: For example, BBR favors flows with a high \gls{rtt}, while New Reno favors those with a low one \cite{turkovic_interactions_2019,turkovic_fifty_2019}. This unfairness can be mitigated by using \gls{fq} at the bottleneck link, isolating each flow from all other flows and assigning each flow an equal share of bandwidth \cite{dumazet_pkt_sched:_2013}. 

The question of how to manage each queue then arises: The simplest solution is using a static buffer size (queue size) for each flow. Another solution is to use an advanced \gls{aqm} mechanism like CoDel for each flow. CoDel aims to keep the queue length under a certain threshold, making sure that the queuing delay was smaller than 5\;ms in the last 100\;ms at least once. Otherwise it drops packets to decrease the queue length. Both of these approaches do not differentiate between flows: They apply the same logic to each flow no matter its congestion control and no matter the current bandwidth and \gls{rtt}. \cite{bachl_cocoa_2019} showed that this behavior leads to some flows not being able to claim the full bandwidth that they are entitled to. Other flows might achieve the full bandwidth but keep an unnecessary standing queue. \cite{bachl_rax_2019} proposed a mechanism that adjusts the queue of each flow based on its congestion control and showed that it works well for several common \glspl{cca}. However, their algorithm has parameters that have to be manually adjusted and is not guaranteed to work for every \gls{cca} because it makes the assumption that each flow's congestion window follows a zigzag pattern. Furthermore, their approach is only tailored towards flows that always have data to send while the behavior for application limited flows, that also have idle periods, is not clear. 

Instead of a hand-crafted solution like the existing ones, we argue that instead operators of network hardware should be able to simply specify a utility function, and the \gls{aqm} then automatically finds the right queuing policy based on that utility function using \gls{ml}. 

\section{Concept}

\begin{figure}[h]
\includegraphics[width=\columnwidth]{figures/cocoa_illustration_too_little.pdf}
\caption{If the buffer is too small, loss-based \glspl{cca} cannot fully utilize the link since they send too few data following the multiplicative decrease that occurs after packet loss.}
\label{fig:tooLittle}
\end{figure}
\begin{figure}[h]
\includegraphics[width=\columnwidth]{figures/cocoa_illustration_too_much.pdf}
\caption{If the buffer is too large, loss-based \glspl{cca} keep an unnecessary standing queue not required for achieving full link utilization.}
\label{fig:tooMuch}
\end{figure}
\begin{figure}[h]
\includegraphics[width=\columnwidth]{figures/cocoa_illustration_perfect.pdf}
\caption{For a flow controlled by New Reno, if the buffer is the same size as the \gls{bdp}, no standing queue exists and the full bandwidth is achieved.}
\label{fig:perfect}
\end{figure}

If the buffer for a flow is too small, this flow cannot achieve the full bandwidth as shown in \autoref{fig:tooLittle}. On the other side, if the buffer is too large (\autoref{fig:tooMuch}), the flow can achieve the full bandwidth but a standing queue exists, which causes unnecessary delay.  

For the popular \gls{cca} \textit{New Reno}, the buffer size that is necessary in a fair queuing setting is one \gls{bdp}, meaning $\textit{speed}\times\textit{delay}$ (\autoref{fig:perfect}). This is because its multiplicative decrease factor is $0.5$, meaning that after packet loss, the congestion window is halved. For other \glspl{cca} like \textit{Cubic} \cite{ha_cubic:_2008}, the multiplicative decrease factor is $0.7$, meaning that the congestion window is reduced to 70\% of its previous value upon packet loss. This means that the minimum buffer size required to achieve full throughput for a Cubic flow is $\left(\frac{1}{0.7}-1\right)\times \textit{BDP}$, which is around 43\% of the \gls{bdp} and thus less than for New Reno. It follows that an adaptive fair \gls{aqm} must learn the underlying \gls{cca} from a flow to adjust the buffer optimally. 

Because optimal buffer size for many \glspl{cca} depends on the \gls{bdp} and thus on the bandwidth and the delay (\gls{rtt}), for example, a flow only having half the \gls{rtt} of another one only needs half its buffer size to achieve full bandwidth. 

To learn an optimal \gls{aqm} policy, we specify a utility function, which the \gls{ml} based \gls{aqm} then should learn. A simple utility function is for example:

\begin{align}
U = \textit{bandwidth}-\alpha\times\textit{queue size}
\end{align}

In this utility function, the choosable parameter $\alpha$ specifies the tradeoff that is chosen between the bandwidth and the buffer size. With $\alpha$ going to zero, the optimum policy approaches the one in which the buffer size is large enough that a flow never underutilizes the link but at the same time the buffer is never going to be larger than necessary if this doesn't provide a benefit in throughput. 

Our \gls{ml} system uses the above utility function to learn the optimal behavior. \gls{ours} computes features for each flow after every packet it receives and then outputs the optimal buffer size that it deems to maximize the utility function. As the input we use the following features: 
\begin{itemize}
\item queue size
\item standard deviation of the queue size 
\item maximimum allowed buffer size
\item rate of incoming data
\item rate of outgoing data
\item time since the last packet loss
\end{itemize}
We do not use these features directly but instead use 10 exponentially weighted averages of them for each feature with weights of $2^{-4}$, $2^{-5}$, ... , $2^{-13}$. The advantage of using exponentially weighted averages is that they do not occupy any space in memory except for their own values. This is opposed to regular moving averages, which have to keep the entire window of data in memory. 

One difficulty is to get an exponentially moving average for the rate of incoming/outgoing packets because computing the average of rates is mathematically not easily possible: Instead we compute the exponentially moving average of the interarrival times of incoming packets and the interdeparture times of outgoing packets. We then invert this number to get the rate. Another issue here is that numeric instability and division by zero errors can occur using this approach. Thus, we only use the exponential average with a weight of $2^{-n}$ after at least $n$ packets have arrived. Otherwise we set it to zero. 

Using these features gives us a feature vector of $6\times 10 = 60$ features at each point in time. The features are fed into a neural network which has one output: The deemed optimal queue size.  

\subsection{Offline Learning}

First, we implement an \gls{ml} system that is capable of learning an optimal queuing policy in a simulator. The idea is that in an ideal setting training is faster. After training in a simulator, the finished neural network can be deployed in a real production setting. 

The training procedure involves the following steps:
\begin{enumerate}
\item Draw a random sample of bandwidths, delays, \gls{cca} and flow durations.
\item Simulate each flow concurrently, compute the feature vector continuously and let the neural network output its optimal buffer size each time a new packet arrives. 
\item During each flow, at a random time between 0 and the flow length in seconds divided by 2, perform the experiment: Continue one simulation with the current buffer size $+1$ packet and one with the current buffer size $-1$ packet until the end of the flow. 
\item Wait until all flows are finished
\item Check for each flow which of the two versions performed better ($+1$ or $-1$) regarding the utility function.
\item Update the neural network to output the better buffer size when being fed the inputs as they were at the time at which the experimentation started. Specifically, we compute the \gls{mae} between the output of the neural network and the desired output (the one that performed better in the experiment).
\item Start the next iteration. 
\end{enumerate}

During deployment, the trained neural network is used but the experiment step is skipped. 

\subsection{Online Learning}

In contrast to offline learning online learning enables to train in deployment. This makes it possible to adapt the behavior slowly over time (over a time span of month or years), for example if new \glspl{cca} emerge. Furthermore, training with real flows is more realistic than training only with simulated flows in a simulation. 

For online training we need two neural networks: 
\begin{itemize}
\item An actor network, which outputs the optimal buffer size at each time step.
\item A critic network, which outputs the utility that it predicts is going to be achieved when keeping the current buffer size until the end of the flow. 
\end{itemize}
Both of these neural networks have the same number of layers and neurons. 

The training procedure involves the following steps:
\begin{enumerate}
\item Draw a random sample of bandwidths, delays, \gls{cca} and flow durations.
\item Simulate each flow concurrently, compute the feature vector continuously and let the neural network output its optimal buffer size each time a new packet arrives. 
\item During each flow, at a random time between 0 and the flow length in seconds divided by 2, perform the experiment: Continue the simulation either with the current buffer size incremented by 1 or decremented by 1 until the end of the flow. 
\item Wait until all flows are finished
\item Check for each flow if its decision was better than the expectation of the critic network.
\item Update the actor neural network to output the better buffer size when being fed the inputs as they were at the time at which the experimentation started. If the experiment was with buffer size $-1$ but this yielded worse results than expected, this implies that the buffer size $+1$ would have been better. As for offline training we use the \gls{mae}. 
\item Update the critic neural network by using the input vector that was recorded at the time at which the experiment started and the utility that was achieved as the label. Specifically, \gls{mse} is used as the loss function. 
\item Start the next iteration. 
\end{enumerate}

\section{Implementation} 

We implement \gls{ours} in the network simulator ns-3 \cite{nsnam_ns-3_nodate} and integrate Pytorch's \cite{paszke_pytorch_2019} C++ API into ns-3 for the \gls{dl}. 

For the simulations we randomly draw a bandwidth (5 to 25\;Mbit/s), a delay (5 to 25\;ms) and duration (3.75\;ms to 6.25\;ms) and a \gls{cca} (New Reno or BIC \cite{lisong_xu_binary_2004}). We use New Reno because it is one of the oldest, most widely deployed \glspl{cca} and BIC because it is similar to Cubic, which is the default in Linux, Windows and most other OSs currently. We cannot use Cubic itself because there is no stable Cubic implementation in ns-3 currently. As the experiment time (the time at which the experiment is launched to determine if a larger or smaller buffer size would be better), we use a random number between 0 and half of the flow duration of the current flow. 

For the simulation we use two hosts that are directly connected to each other. We also experimented initially with a switch connecting these hosts, however, the simulation was a significantly slower. Thus we made the simulation as simple as possible and implemented our \gls{aqm} in front of the bottleneck link, that connects the sender to the receiver. For all other buffers we use a FIFO queue with a buffer of 100 packets (the default). 

One major issue that we encountered bufferbloat (over 100\;ms even if we set our buffers to 1 packet). The reason was that ns-3 also has a additional buffer for each link: First, there's the buffer of the queuing discipline (for which we implement our mechanism) and then there's also a hardware buffer after that. This buffer has a default queue size of 100 packets as well. Thus, on a 10\;Mbit/s link, this hardware buffer alone results in a delay of 120\;ms when simulating bulk transfers. We reduced this buffer to 1 packet and then found the simulations to behave as expected. 

For the \gls{dl}, we used a fully connected neural network consisting of an input layer, three layers of 256 neurons which each have the leaky ReLU \cite{noauthor_rectifier_2020} function applied and finally an output layer which has an output size of 1. All neural networks we use have this architecture. For the learning we chose gradient descent with a learning rate of $0.01$. 

\subsection{Offline Learning}

We chose to run 20 simulations concurrently since our computers have 40 CPUs and every simulation is split in two at the time of the experiment. Thus with 20 simulations we fully utilize the 20 CPUs. This implies that the batch size used for the \gls{dl} is 20. 

\subsection{Online Learning}

For online learning we run 40 simulations concurrently since we have 40 CPUs and online learning does not split each simulation into two as it happens for offline learning. The batch size for the \gls{dl} is thus 40. 

\section{Results}

\todo{Include vectorized figures instead of rasterized ones. Include axes labels.}

\subsection{Offline Learning}

\begin{figure}[h]
\includegraphics[width=\columnwidth]{/mnt/cluster/results/RLQueueDisc/logs/plots/2020-6-6-10-24-18_prediction.png}
\caption{The prediction of the optimal buffer by the neural network during training.}
\label{fig:offlineTraining}
\end{figure}
\begin{figure}[h]
\includegraphics[width=\columnwidth]{/mnt/cluster/results/RLQueueDisc/logs/plots/2020-6-6-10-24-18_prediction.png}
\caption{The prediction of the optimal buffer by the neural network during training.}
\label{fig:offlineTraining}
\end{figure}


\begin{figure*}[h]
\centering
\subfloat[New Reno, varying bandwidth.\label{fig:SmallAlphaNewRenoBandwidth}
]{
\includegraphics[width=0.98\columnwidth]{{"../ns-allinone-3.30.1/ns-3.30.1/results/RLQueueDisc/logs/plots/2020-6-6-10-24-18_26000.weights_New Reno_bandwidth"}.pdf}
}{}
\subfloat[New Reno, varying delay.\label{fig:SmallAlphaNewRenoDelay}
]{
\includegraphics[width=0.98\columnwidth]{{"../ns-allinone-3.30.1/ns-3.30.1/results/RLQueueDisc/logs/plots/2020-6-6-10-24-18_26000.weights_New Reno_delay"}.pdf}
}{}
\subfloat[BIC, varying bandwidth\label{fig:SmallAlphaBicBandwidth}
]{
\includegraphics[width=0.98\columnwidth]{{"../ns-allinone-3.30.1/ns-3.30.1/results/RLQueueDisc/logs/plots/2020-6-6-10-24-18_26000.weights_Bic_bandwidth"}.pdf}
}{}
\subfloat[BIC, varying delay\label{fig:SmallAlphaBicDelay}
]{
\includegraphics[width=0.98\columnwidth]{{"../ns-allinone-3.30.1/ns-3.30.1/results/RLQueueDisc/logs/plots/2020-6-6-10-24-18_26000.weights_Bic_delay"}.pdf}
}{}
\caption{Change of the buffer size after offline learning when varying bandwidth/delay/\gls{cca}, keeping the other parameters constant at their mean. \todo{Smaller margin for figures.}}
\label{fig:offlineSmallAlpha}
\end{figure*}

\subsubsection{$\alpha=0.01$}

When performing offline learning with the tradeoff parameter $\alpha=0.01$ (\autoref{fig:offlineTraining}), the neural network first starts with a prediction that is close to 0 (due to the initialization of neural network weights). During the first couple of thousand training flows, it increases its output and approaches what appears to be the buffer size that works best on average (slightly higher than 15). Then the neural network starts differentiating different flow and learn custom policies for them. After around 250000 flows, the output appears to be stable and doesn't change anymore. There's one noticeable outlier at around 120000 flows. This appears to be some instability that can commonly occur in the early stages of neural network training. 

When the neural network is sufficiently trained, the behavior of the queuing policy can be observed by testing it (\autoref{fig:offlineSmallAlpha}). The plots show the behavior when the parameter on the x-axis is changed on the average queue length, the maximum allowed queue length and on the throughput. 

As expected, when increasing the bandwidth, the neural network outputs a larger maximum queue size, because a larger buffer is needed for New Reno and BIC, when the bandwidth is larger. However, learning the relationship is not difficult: In fact, the neural network would simply need to learn to use the identity function to map the input feature than encodes the incoming or outgoing data rate to the output. 

The results also show that increasing the delay increases the output of the neural network. This is more interesting than for the bandwidth since no input feature directly encodes the delay. Thus, the neural network must observe the pattern of the \gls{cca}, estimate the \gls{rtt} and output the suitable maximum queue size. The right column of \autoref{fig:offlineSmallAlpha} shows that there is clearly a linear relationship between the delay and the output maximum queue size. 

Finally, since BIC has a different multiplicative decrease factor than New Reno ($0.8$ vs $0.5$) the neural network should learn to output different maximum queue sizes for these two. Specifically, we would expect BIC to need a smaller buffer as its decrease is smaller, thus requiring a smaller buffer. Indeed, when comparing the top vs.~the bottom row, the results in \autoref{fig:offlineSmallAlpha} show that the buffer is significantly smaller for BIC than it is for New Reno on average. 

\begin{table}[h]
\caption{Comparing classification metrics per flow with either discrete (20 different actions) or continuous actions. The tradeoff is always $0.1$.} \label{tab:corrOfflineSmallAlpha}
\centering
\begin{tabular}{lrr} \toprule
\gls{cca} & bandwidth & delay \\ \midrule
New Reno & 95.5\% & 95.7\% \\
BIC & 70.6\% & 73.3\% \\
\bottomrule
\end{tabular}
\end{table}

While the results look as expected, it is better to have a quantifiable measure. For this, we compute the correlation between the value on the x-axis and the maximum queue size output by the neural network. If the neural network learned ideally, the correlation obtained would be 1. \autoref{tab:corrOfflineSmallAlpha} shows that the for New Reno the correlation is very high while for BIC it is high but not as good as for New Reno. We attribute this to the fact that for BIC the buffer that is required is generally smaller (only a couple of packets) and thus fluctuations in the training process are more pronounced. 

\begin{table}[h]
\caption{The average maximum queue length (in packets) output by the neural network when averaging over all values shown in \autoref{fig:offlineSmallAlpha}.} \label{tab:avgOfflineSmallAlpha}
\centering
\begin{tabular}{lr} \toprule
\gls{cca} & avg.~max.~queue length \\ \midrule
New Reno & 23 \\
BIC & 10 \\
\bottomrule
\end{tabular}
\end{table}

\autoref{tab:avgOfflineSmallAlpha} shows that the average output maximum queue size is more than double for New Reno than for BIC. This shows that the neural network also learned to distinguish between these two \glspl{cca}. Since there are no features that directly indicate the \gls{cca}, the neural network must have learned these by combining the other features and observing distinct behavior for New Reno and BIC. 

\subsubsection{$\alpha=0.01$}

\begin{table}[h]
\caption{Comparing classification metrics per flow with either discrete (20 different actions) or continuous actions. The tradeoff is always $0.1$.} \label{tab:corrOfflineLargeAlpha}
\centering
\begin{tabular}{lrr} \toprule
\gls{cca} & bandwidth & delay \\ \midrule
New Reno & 95.3\% & 93.7\% \\
BIC & 68.2\% & 65.7\% \\
\bottomrule
\end{tabular}
\end{table}

\begin{table}[h]
\caption{The average maximum queue length (in packets) output by the neural network when averaging over all values shown in \autoref{fig:offlineSmallAlpha}.} \label{tab:avgOfflineLargeAlpha}
\centering
\begin{tabular}{lr} \toprule
\gls{cca} & avg.~max.~queue length \\ \midrule
New Reno & 12 \\
BIC & 5 \\
\bottomrule
\end{tabular}
\end{table}

Results in \autoref{tab:corrOfflineLargeAlpha} and \autoref{tab:corrOfflineSmallAlpha} show that for a larger $\alpha$ \gls{ours} still works as expected and that the average output maximum queue size is smaller, as expected. 

\subsection{Online Learning}

\section{Discussion}

\bibliographystyle{ACM-Reference-Format}
\bibliography{reference}

\end{document}
